In this work, we have investigated summarization systems and how positional biases affect these systems' learning process. Motivated by \cite{kedzie2018content}'s work and our own experiments showing that current summarization systems are heavily affected by positional cues, we design novel methods to counter the dominance of these signals.

Our first method involves augmenting an existing gradient descent-based summarization model with an auxiliary loss objective. For a given input article, this loss objective estimates each sentence's value by computing the sentence-level ROUGE score compared to the reference summary. It then encourages the model to match these sentence-value estimates using the KL divergence between the model's predictions and the estimates. We test this method with a state-of-the-art summarization system, BanditSum \parencite{dong2018banditsum}, and find that our method can significantly improve summary quality. 

Although the improvements are noteworthy, the resulting model is still hampered by an overreliance on lead bias. Evidence for this lingering issue is seen in Figure \ref{fig:avg_pos}, as the oracle summarizer extracts leading sentences far less than the BanditSum+KL method. Some extensions to this method could include other algorithms to combine the loss functions such as MAML \parencite{maml}, or investigating RL methods aimed at promoting exploration such as the Soft-Actor Critic algorithm \parencite{sac}.

After hypothesizing that articles with a strong vs. weak lead require different summarization strategies, we design a second novel summarization method based around classifying whether an article's lead contains summary-worthy sentences. We find that by partitioning the training dataset and training separate summarization systems on these subsets, we can achieve greater performance on both subsets. We note that in the case of the \Dearly{} subset, the model's learning is dominated by positional bias, and it learns to mimic the lead-3 baseline exactly. Training a classifier proves to be a much more difficult task, especially with regards to overfitting.

% Limitations
Assuming an accurate classifier is achievable, future summarization approaches may render this approach redundant. Emerging summarization models, such as BertSum and BART \parencite{bertsum, lewis2019bart}, have taken advantage of large unsupervised language model pre-training in their approaches. In particular, the authors of BertSum show that their method is able extract sentences further in the document compared to a competitive baseline, and that the extracted indices are more similar to an oracle summarizer. Compared to previous models such as BanditSum, BertSum is more robust with respect to lead bias effects, despite having no explicit target objective aimed at countering this damaging signal. This may mean that explicit lead bias regularization is not necessary, as long as the model can sufficiently balance positional cues with semantic ones.

% Conclude: lead bias is an important factor for summarization
Regardless of how future summarization models operate, we have shown that positional biases are an important consideration when designing summarization systems. Creating models that understand how to properly balance positional cues and value sentences correctly represents a major milestone towards truly practical summarization systems.
