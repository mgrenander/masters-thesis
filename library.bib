

@inproceedings{schiffman,
 author = {Schiffman, Barry and Nenkova, Ani and McKeown, Kathleen},
 title = {Experiments in Multidocument Summarization},
 booktitle = {Proceedings of the Second International Conference on Human Language Technology Research},
 year = {2002},
 pages = {52--58},
 numpages = {7},
 } 

@article{kiperwasser2018scheduled,
  title={Scheduled Multi-Task Learning: From Syntax to Translation},
  author={Kiperwasser, Eliyahu and Ballesteros, Miguel},
  journal={Transactions of the Association of Computational Linguistics},
  volume={6},
  pages={225--240},
  year={2018}
}

@inproceedings{grusky2018newsroom,
  title={Newsroom: A Dataset of 1.3 Million Summaries with Diverse Extractive Strategies},
  author={Grusky, Max and Naaman, Mor and Artzi, Yoav},
  booktitle={Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)},
  volume={1},
  pages={708--719},
  year={2018}
}

@inproceedings{narayan2018don,
  title={Don't Give Me the Details, Just the Summary! Topic-Aware Convolutional Neural Networks for Extreme Summarization},
  author={Narayan, Shashi and Cohen, Shay B and Lapata, Mirella},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={1797--1807},
  year={2018}
}

@article{sandhaus2008new,
  title={The new york times annotated corpus},
  author={Sandhaus, Evan},
  journal={Linguistic Data Consortium, Philadelphia},
  volume={6},
  number={12},
  pages={e26752},
  year={2008}
}

@article{brandow1995automatic,
  title={Automatic condensation of electronic publications by sentence selection},
  author={Brandow, Ronald and Mitze, Karl and Rau, Lisa F},
  journal={Information Processing \& Management},
  volume={31},
  number={5},
  pages={675--685},
  year={1995},
  publisher={Elsevier}
}

@inproceedings{nenkova2005automatic,
  title={Automatic text summarization of newswire: Lessons learned from the document understanding conference},
  author={Nenkova, Ani},
  booktitle={AAAI},
  volume={5},
  pages={1436--1441},
  year={2005}
}

@inproceedings{hong2014improving,
  title={Improving the estimation of word importance for news multi-document summarization},
  author={Hong, Kai and Nenkova, Ani},
  booktitle={Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics},
  pages={712--721},
  year={2014}
}

@inproceedings{kedzie2018content,
  title={Content Selection in Deep Learning Models of Summarization},
  author={Kedzie, Chris and McKeown, Kathleen and Daume III, Hal},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={1818--1828},
  year={2018}
}

@inproceedings{dong2018banditsum,
  title={BanditSum: Extractive Summarization as a Contextual Bandit},
  author={Dong, Yue and Shen, Yikang and Crawford, Eric and van Hoof, Herke and Cheung, Jackie Chi Kit},
  booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing},
  pages={3739--3748},
  year={2018}
}

@inproceedings{hermann2015teaching,
  title={Teaching machines to read and comprehend},
  author={Hermann, Karl Moritz and Kocisky, Tomas and Grefenstette, Edward and Espeholt, Lasse and Kay, Will and Suleyman, Mustafa and Blunsom, Phil},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1693--1701},
  year={2015}
}

@inproceedings{vinyals2015pointer,
  title={Pointer networks},
  author={Vinyals, Oriol and Fortunato, Meire and Jaitly, Navdeep},
  booktitle={Advances in Neural Information Processing Systems (NIPS)},
  pages={2692--2700},
  year={2015}
}

@inproceedings{chen2018abstractive,
  title     = {Fast Abstractive Summarization with Reinforce-Selected Sentence Rewriting},
  author    = {Yen{-}Chun Chen and
               Mohit Bansal},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2018}
}

@inproceedings{tan2017abstractive,
  title={Abstractive document summarization with a graph-based attentional neural model},
  author={Tan, Jiwei and Wan, Xiaojun and Xiao, Jianguo},
  booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL)},
  volume={1},
  pages={1171--1181},
  year={2017}
}

@inproceedings{tra_ext5_wong2008extractive,
  title={Extractive summarization using supervised and semi-supervised learning},
  author={Wong, Kam-Fai and Wu, Mingli and Li, Wenjie},
  booktitle={Proceedings of the 22nd International Conference on Computational Linguistics (COLING)},
  pages={985--992},
  year={2008}
}

@inproceedings{tra_ext4_conroy2001text,
  title={Text summarization via hidden markov models},
  author={Conroy, John M and O'leary, Dianne P},
  booktitle={Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={406--407},
  year={2001},
  organization={ACM}
}

@inproceedings{tra_ext3_mihalcea2004textrank,
  title={Text{R}ank: Bringing order into text},
  author={Mihalcea, Rada and Tarau, Paul},
  booktitle={Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2004}
}

@inproceedings{tra_ext2_gong2001generic,
  title={Generic text summarization using relevance measure and latent semantic analysis},
  author={Gong, Yihong and Liu, Xin},
  booktitle={Proceedings of the 24th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval},
  pages={19--25},
  year={2001},
  organization={ACM}
}

@article{tra_ext1_luhn1958automatic,
  title={The automatic creation of literature abstracts},
  author={Luhn, Hans Peter},
  journal={IBM Journal of Research and Development},
  volume={2},
  number={2},
  pages={159--165},
  year={1958},
  publisher={IBM}
}

@inproceedings{shen2016minimum,
  title={Minimum Risk Training for Neural Machine Translation},
  author={Shen, Shiqi and Cheng, Yong and He, Zhongjun and He, Wei and Wu, Hua and Sun, Maosong and Liu, Yang},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics},
  volume={1},
  pages={1683--1692},
  year={2016}
}

@article{Ranzato2015SequenceLT,
  title={Sequence level training with recurrent neural networks},
  author={Ranzato, Marc'Aurelio and Chopra, Sumit and Auli, Michael and Zaremba, Wojciech},
  journal={arXiv preprint arXiv:1511.06732},
  year={2015}
}


@inproceedings{lu2010contextual,
  title={Contextual multi-armed bandits},
  author={Lu, Tyler and P{\'a}l, D{\'a}vid and P{\'a}l, Martin},
  booktitle={Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS)},
  pages={485--492},
  year={2010}
}

@inproceedings{DBLP:Narayan/2018,
  author    = {Shashi Narayan and
               Shay B. Cohen and
               Mirella Lapata},
  title     = {Ranking Sentences for Extractive Summarization with Reinforcement Learning},
  booktitle  = {Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL)},
  year      = {2018}
}

@inproceedings{DBLP:conf/aaai/WuH18,
  author    = {Yuxiang Wu and
               Baotian Hu},
  title     = {Learning to Extract Coherent Summary via Deep Reinforcement Learning},
  booktitle = {Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2018},
  crossref  = {DBLP:conf/aaai/2018},
  url       = {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16838},
  timestamp = {Thu, 03 May 2018 17:03:19 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/aaai/WuH18},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@proceedings{DBLP:conf/aaai/2018,
  editor    = {Sheila A. McIlraith and
               Kilian Q. Weinberger},
  title     = {Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI)},
  year      = {2018},
  url       = {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/schedConf/presentations},
  timestamp = {Thu, 03 May 2018 17:02:03 +0200},
  biburl    = {https://dblp.org/rec/bib/conf/aaai/2018},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{yasunaga2017graph,
  title={Graph-based Neural Multi-Document Summarization},
  author={Yasunaga, Michihiro and Zhang, Rui and Meelu, Kshitijh and Pareek, Ayush and Srinivasan, Krishnan and Radev, Dragomir},
  booktitle={Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL)},
  year={2017},
  pages={452--462},
}

@article{DBLP:journals/corr/NguyenDB17,
  author    = {Khanh Nguyen and
               Hal Daum{\'{e}} III and
               Jordan L. Boyd{-}Graber},
  title     = {Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback},
  journal   = {CoRR},
  volume    = {abs/1707.07402},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.07402},
  archivePrefix = {arXiv},
  eprint    = {1707.07402},
  timestamp = {Sat, 05 Aug 2017 14:56:06 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/NguyenDB17},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}


@inproceedings{rl_ryang2012frameworkRL,
  title={Framework of automatic text summarization using reinforcement learning},
  author={Ryang, Seonggi and Abekawa, Takeshi},
  booktitle={Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP)},
  pages={256--265},
  year={2012}
}

@article{lin2017structuredSelfAttention,
  title={A structured self-attentive sentence embedding},
  author={Lin, Zhouhan and Feng, Minwei and Santos, Cicero Nogueira dos and Yu, Mo and Xiang, Bing and Zhou, Bowen and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1703.03130},
  year={2017}
}


@inproceedings{vaswani2017attentionTransformer,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in Neural Information Processing Systems},
  pages={6000--6010},
  year={2017}
}

@article{arumae2018reinforced,
  title={Reinforced Extractive Summarization with Question-Focused Rewards},
  author={Arumae, Kristjan and Liu, Fei},
  journal={Proceedings of ACL 2018, Student Research Workshop},
  year={2018}
}


@inproceedings{haghighi2009evalAbTest,
  title={Exploring content models for multi-document summarization},
  author={Haghighi, Aria and Vanderwende, Lucy},
  booktitle={Human Language Technologies: the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)},
  pages={362--370},
  year={2009}
}


@inproceedings{abs1_RushCW15,
  author    = {Alexander M. Rush and
               Sumit Chopra and
               Jason Weston},
  title     = {A Neural Attention Model for Abstractive Sentence Summarization},
  booktitle = {Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages     = {379--389},
  year      = {2015},
  url       = {http://aclweb.org/anthology/D/D15/D15-1044.pdf},
  timestamp = {Wed, 14 Oct 2015 09:56:24 +0200},
  biburl    = {http://dblp.org/rec/bib/conf/emnlp/RushCW15},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{abs2_ChopraAR16,
  author    = {Sumit Chopra and
               Michael Auli and
               Alexander M. Rush},
  title     = {Abstractive Sentence Summarization with Attentive Recurrent Neural Networks},
  booktitle = {Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
  pages     = {93--98},
  year      = {2016},
  url       = {http://aclweb.org/anthology/N/N16/N16-1012.pdf},
  timestamp = {Tue, 13 Sep 2016 20:32:15 +0200},
  biburl    = {http://dblp.org/rec/bib/conf/naacl/ChopraAR16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{abs3_NallapatiZSGX16,
  author    = {Ramesh Nallapati and
               Bowen Zhou and
               C{\'{\i}}cero Nogueira dos Santos and
               {\c{C}}aglar G{\"{u}}l{\c{c}}ehre and
               Bing Xiang},
  title     = {Abstractive Text Summarization using Sequence-to-sequence {RNNs} and
               Beyond},
  booktitle = {Conference on Computational Natural
               Language Learning (CoNLL)},
  pages     = {280--290},
  year      = {2016},
  url       = {http://aclweb.org/anthology/K/K16/K16-1028.pdf},
  timestamp = {Fri, 02 Sep 2016 09:34:40 +0200},
  biburl    = {http://dblp.org/rec/bib/conf/conll/NallapatiZSGX16},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{abs4_SeeLM17,
  author    = {Abigail See and
               Peter J. Liu and
               Christopher D. Manning},
  title     = {Get To The Point: Summarization with Pointer-Generator Networks},
  booktitle={Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (ACL)},
  pages     = {1073--1083},
  year      = {2017},
  url       = {https://doi.org/10.18653/v1/P17-1099},
  doi       = {10.18653/v1/P17-1099},
  timestamp = {Fri, 04 Aug 2017 16:38:24 +0200},
  biburl    = {http://dblp.org/rec/bib/conf/acl/SeeLM17},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}


@inproceedings{
abs5_paulus2017deep,
title={A Deep Reinforced Model for Abstractive Summarization},
author={Romain Paulus and Caiming Xiong and Richard Socher},
booktitle={International Conference on Learning Representations (ICLR)},
year={2018},
url={https://openreview.net/forum?id=HkAClQgA-},
}


@inproceedings{sim2_conf/emnlp/ZhangL17,
  author    = {Xingxing Zhang and
               Mirella Lapata},
  title     = {Sentence Simplification with Deep Reinforcement Learning},
  booktitle = {Proceedings of the 2017 Conference on Empirical Methods in Natural
               Language Processing (EMNLP)},
  pages     = {595--605},
  year      = {2017},
  url       = {http://aclanthology.info/papers/D17-1063/d17-1063},
  timestamp = {Fri, 15 Sep 2017 17:29:55 +0200},
  biburl    = {http://dblp.org/rec/bib/conf/emnlp/ZhangL17},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}


@inproceedings{rl1_bahdanau+al-2017-actorcritic-iclr,
  title={An actor-critic algorithm for sequence prediction},
  author={Bahdanau, Dzmitry and Brakel, Philemon and Xu, Kelvin and Goyal, Anirudh and Lowe, Ryan and Pineau, Joelle and Courville, Aaron and Bengio, Yoshua},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2017},
 
}

International Conference on Learning Representations
@article{sim1_journals/tacl/XuCN15,
  author    = {Wei Xu and
               Chris Callison{-}Burch and
               Courtney Napoles},
  title     = {Problems in Current Text Simplification Research: New Data Can Help},
  journal   = {Transactions of the Association for Computational Linguistics},
  volume    = {3},
  pages     = {283--297},
  year      = {2015},
  url       = {https://tacl2013.cs.columbia.edu/ojs/index.php/tacl/article/view/549},
}

@inproceedings{eval3_haghighi2009exploring,
  title={Exploring content models for multi-document summarization},
  author={Haghighi, Aria and Vanderwende, Lucy},
  booktitle={Proceedings of Human Language Technologies: the 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics},
  pages={362--370},
  year={2009},
  organization={Association for Computational Linguistics}
}

@inproceedings{eva2_conf/naacl/NenkovaP04,
  author    = {Ani Nenkova and
               Rebecca J. Passonneau},
  title     = {Evaluating Content Selection in Summarization: The Pyramid Method},
  booktitle = {Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics: Hlt-naacl},
  pages     = {145--152},
  year      = {2004},
  url       = {http://aclweb.org/anthology/N/N04/N04-1019.pdf},
  timestamp = {Mon, 19 Dec 2016 14:34:51 +0100}
}

@inproceedings{eva1_lin:2004:ACLsummarization,
  author    = {Lin, Chin-Yew},
  title     = {ROUGE: A Package for Automatic Evaluation of Summaries},
  booktitle = {Text Summarization Branches Out: Proceedings of the ACL-04 Workshop},
  editor = {Marie-Francine Moens, Stan Szpakowicz},
  year      = 2004,
  month     = {July},
 
}

@article{kalchbrenner2014convolutional,
  title={A convolutional neural network for modelling sentences},
  author={Kalchbrenner, Nal and Grefenstette, Edward and Blunsom, Phil},
  journal={arXiv preprint arXiv:1404.2188},
  year={2014}
} 

@inproceedings{ext1_kaageback2014extractive,
  title={Extractive summarization using continuous vector space models},
  author={K{\aa}geb{\"a}ck, Mikael and Mogren, Olof and Tahmasebi, Nina and Dubhashi, Devdatt},
  booktitle={Workshop on Continuous Vector Space Models and their Compositionality (CVSC) at EACL},
  pages={31--39},
  year={2014}
}

@inproceedings{ext2_2015Yin,
  author    = {Wenpeng Yin and
               Yulong Pei},
  title     = {Optimizing Sentence Modeling and Selection for Document Summarization},
  booktitle = {Proceedings of the 24th International Joint Conference on Artificial Intelligence (IJCAI)},
  pages     = {1383--1389},
  year      = {2015},
  url       = {http://ijcai.org/Abstract/15/199},
  timestamp = {Wed, 01 Feb 2017 10:49:14 +0100}
}

@inproceedings{ext3_cao2015learning,
  title={Learning Summary Prior Representation for Extractive Summarization.},
  author={Cao, Ziqiang and Wei, Furu and Li, Sujian and Li, Wenjie and Zhou, Ming and Wang, Houfeng},
  year={2015},
  booktitle={Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics}
}

@inproceedings{ext4_cheng2016neural,
  title={Neural summarization by extracting sentences and words},
  author={Cheng, Jianpeng and Lapata, Mirella},
  booktitle={Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2016}
}

@inproceedings{ext5_summarunner,
  author    = {Ramesh Nallapati and
               Feifei Zhai and
               Bowen Zhou},
  title     = {Summa{R}u{NN}er: {A} Recurrent Neural Network Based Sequence Model for Extractive Summarization of Documents},
  booktitle = {Proceedings of the 31st AAAI Conference on Artificial Intelligence},
  year      = {2017}
}


@article{attn1_bahdanau2014neural,
  title={Neural machine translation by jointly learning to align and translate},
  author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
  journal={arXiv preprint arXiv:1409.0473},
  year={2014}
}

@article{attn2_gehring2017cnn,
  title={Convolutional sequence to sequence learning},
  author={Gehring, Jonas and Auli, Michael and Grangier, David and Yarats, Denis and Dauphin, Yann N},
  journal={arXiv preprint arXiv:1705.03122},
  year={2017}
}

@inproceedings{cnn1_kalchbrenner2014convolutional,
  title={A convolutional neural network for modelling sentences},
  author={Kalchbrenner, Nal and Grefenstette, Edward and Blunsom, Phil},
  booktitle={Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL)},
  year={2014}
}

@inproceedings{cnn2_kim2014convolutional,
  title={Convolutional neural networks for sentence classification},
  author={Kim, Yoon},
  booktitle={Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  year={2014}
}

@article{rnn1_hochreiter1997lstm,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}


@inproceedings{rnn2_chung2014gru,
title = "Empirical evaluation of gated recurrent neural networks on sequence modeling",
author = "Junyoung Chung and Caglar Gulcehre and Kyunghyun Cho and Yoshua Bengio",
year = "2014",
language = "English (US)",
booktitle = "NIPS 2014 Workshop on Deep Learning",
}

@inproceedings{we1_mikolov2013efficient,
  title={Efficient estimation of word representations in vector space},
  author={Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey},
  booktitle={International Conference on Learning Representations (ICLR) Workshop},
  year={2013}
}

@inproceedings{we2_pennington2014glove,
  title={Glove: Global vectors for word representation},
  author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher},
  booktitle={Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={1532--1543},
  year={2014}
}

@article{yao2018deep,
  title={Deep reinforcement learning for extractive document summarization},
  author={Yao, Kaichun and Zhang, Libo and Luo, Tiejian and Wu, Yanjun},
  journal={Neurocomputing},
  volume={284},
  pages={52--62},
  year={2018},
  publisher={Elsevier}
}

@inproceedings{agarwal2014taming,
  title={Taming the monster: A fast and simple algorithm for contextual bandits},
  author={Agarwal, Alekh and Hsu, Daniel and Kale, Satyen and Langford, John and Li, Lihong and Schapire, Robert},
  booktitle={International Conference on Machine Learning (ICML)},
  pages={1638--1646},
  year={2014}
}

@incollection{williams1992simple,
  title={Simple statistical gradient-following algorithms for connectionist reinforcement learning},
  author={Williams, Ronald J},
  booktitle={Reinforcement Learning},
  pages={5--32},
  year={1992},
  publisher={Springer}
}

@inproceedings{rennie2017self,
  title={Self-Critical Sequence Training for Image Captioning},
  author={Rennie, Steven J and Marcheret, Etienne and Mroueh, Youssef and Ross, Jerret and Goel, Vaibhava},
  booktitle={IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
  pages={7008--7024},
  year={2017}
}

@inproceedings{sutton2000policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David A and Singh, Satinder P and Mansour, Yishay},
  booktitle={Advances in Neural Information Processing Systems (NIPS)},
  pages={1057--1063},
  year={2000}
}

@inproceedings{data2_nallapati2016abstractive,
  title={Abstractive text summarization using sequence-to-sequence rnns and beyond},
  author={Nallapati, Ramesh and Zhou, Bowen and  dos Santos, Cicero and G\.{u}l\c{c}ehre, \c{C}a\u{g}lar and Xiang, Bing},
  booktitle={Proceedings of the 20th SIGNLL Conference on Computational Natural Language Learning (CoNLL)},
  year={2016}
}

@inproceedings{data3_kikuchi2016learning,
  title={Learning from numerous untailored summaries},
  author={Kikuchi, Yuta and Watanabe, Akihiko and Ryohei, Sasano and Takamura, Hiroya and Okumura, Manabu},
  booktitle={Pacific Rim International Conference on Artificial Intelligence},
  pages={206--219},
  year={2016},
  organization={Springer}
}

@inproceedings{adam_kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  booktitle={International Conference for Learning Representations (ICLR)},
  year={2015}
}

@inproceedings{rl_rioux2014fear,
  title={Fear the reaper: A system for automatic multi-document summarization with reinforcement learning},
  author={Rioux, Cody and Hasan, Sadid A and Chali, Yllias},
  booktitle={Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={681--690},
  year={2014}
}

@inproceedings{conroy2001text,
  title={Text summarization via hidden markov models},
  author={Conroy, John M and O'leary, Dianne P},
  booktitle={Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={406--407},
  year={2001},
  organization={ACM}
}

@inproceedings{conroy2001text,
  title={Text summarization via hidden markov models},
  author={Conroy, John M and O'leary, Dianne P},
  booktitle={Proceedings of the 24th annual international ACM SIGIR conference on Research and development in information retrieval},
  pages={406--407},
  year={2001},
  organization={ACM}
}

@article{galashov2019information,
  title={Information asymmetry in KL-regularized RL},
  author={Galashov, Alexandre and Jayakumar, Siddhant M and Hasenclever, Leonard and Tirumala, Dhruva and Schwarz, Jonathan and Desjardins, Guillaume and Czarnecki, Wojciech M and Teh, Yee Whye and Pascanu, Razvan and Heess, Nicolas},
  journal={International Conference on Learning Representations (ICLR)},
  year={2019}
}

@inproceedings{nachum2017bridging,
  title={Bridging the gap between value and policy based reinforcement learning},
  author={Nachum, Ofir and Norouzi, Mohammad and Xu, Kelvin and Schuurmans, Dale},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2775--2785},
  year={2017}
}


@inproceedings{nachum2017improving,
  title={Improving policy gradient by exploring under-appreciated rewards},
  author={Nachum, Ofir and Norouzi, Mohammad and Schuurmans, Dale},
  booktitle={International Conference on Learning Representations},
  pages={2775--2785},
  year={2017}
}

@book{sutton,
 author = {Sutton, Richard S. and Barto, Andrew G.},
 title = {Reinforcement Learning: An Introduction},
 year = {2018},
 isbn = {0262039249, 9780262039246},
 publisher = {A Bradford Book},
 address = {USA},
} 


@InProceedings{maml,
  title = 	 {Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks},
  author = 	 {Chelsea Finn and Pieter Abbeel and Sergey Levine},
  booktitle = 	 {Proceedings of the 34th International Conference on Machine Learning},
  pages = 	 {1126--1135},
  year = 	 {2017},
  editor = 	 {Doina Precup and Yee Whye Teh},
  volume = 	 {70},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {International Convention Centre, Sydney, Australia},
  month = 	 {06--11 Aug},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v70/finn17a/finn17a.pdf},
  url = 	 {http://proceedings.mlr.press/v70/finn17a.html},
  abstract = 	 {We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.}
}

@InProceedings{sac,
  title = 	 {Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning with a Stochastic Actor},
  author = 	 {Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  booktitle = 	 {Proceedings of the 35th International Conference on Machine Learning},
  pages = 	 {1861--1870},
  year = 	 {2018},
  editor = 	 {Dy, Jennifer and Krause, Andreas},
  volume = 	 {80},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Stockholmsmässan, Stockholm Sweden},
  month = 	 {10--15 Jul},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v80/haarnoja18b/haarnoja18b.pdf},
  url = 	 {http://proceedings.mlr.press/v80/haarnoja18b.html},
  abstract = 	 {Model-free deep reinforcement learning (RL) algorithms have been demonstrated on a range of challenging decision making and control tasks. However, these methods typically suffer from two major challenges: very high sample complexity and brittle convergence properties, which necessitate meticulous hyperparameter tuning. Both of these challenges severely limit the applicability of such methods to complex, real-world domains. In this paper, we propose soft actor-critic, an off-policy actor-critic deep RL algorithm based on the maximum entropy reinforcement learning framework. In this framework, the actor aims to maximize expected reward while also maximizing entropy. That is, to succeed at the task while acting as randomly as possible. Prior deep RL methods based on this framework have been formulated as Q-learning methods. By combining off-policy updates with a stable stochastic actor-critic formulation, our method achieves state-of-the-art performance on a range of continuous control benchmark tasks, outperforming prior on-policy and off-policy methods. Furthermore, we demonstrate that, in contrast to other off-policy algorithms, our approach is very stable, achieving very similar performance across different random seeds.}
}

@article{ext_bert,
  author    = {Yang Liu},
  title     = {Fine-tune {BERT} for Extractive Summarization},
  journal   = {CoRR},
  volume    = {abs/1903.10318},
  year      = {2019},
  url       = {http://arxiv.org/abs/1903.10318},
  archivePrefix = {arXiv},
  eprint    = {1903.10318},
  timestamp = {Mon, 01 Apr 2019 14:07:37 +0200},
  biburl    = {https://dblp.org/rec/bib/journals/corr/abs-1903-10318},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@inproceedings{neusum,
    title = "Neural Document Summarization by Jointly Learning to Score and Select Sentences",
    author = "Zhou, Qingyu  and
      Yang, Nan  and
      Wei, Furu  and
      Huang, Shaohan  and
      Zhou, Ming  and
      Zhao, Tiejun",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-1061",
    pages = "654--663",
    abstract = "Sentence scoring and sentence selection are two main steps in extractive document summarization systems. However, previous works treat them as two separated subtasks. In this paper, we present a novel end-to-end neural network framework for extractive document summarization by jointly learning to score and select sentences. It first reads the document sentences with a hierarchical encoder to obtain the representation of sentences. Then it builds the output summary by extracting sentences one by one. Different from previous methods, our approach integrates the selection strategy into the scoring model, which directly predicts the relative importance given previously selected sentences. Experiments on the CNN/Daily Mail dataset show that the proposed framework significantly outperforms the state-of-the-art extractive summarization models.",
}

@inproceedings{dror-hitchhikers,
    title = "The Hitchhiker{'}s Guide to Testing Statistical Significance in Natural Language Processing",
    author = "Dror, Rotem  and
      Baumer, Gili  and
      Shlomov, Segev  and
      Reichart, Roi",
    booktitle = "Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2018",
    address = "Melbourne, Australia",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/P18-1128",
    pages = "1383--1392",
    abstract = "Statistical significance testing is a standard statistical tool designed to ensure that experimental results are not coincidental. In this opinion/ theoretical paper we discuss the role of statistical significance testing in Natural Language Processing (NLP) research. We establish the fundamental concepts of significance testing and discuss the specific aspects of NLP tasks, experimental setups and evaluation measures that affect the choice of significance tests in NLP research. Based on this discussion we propose a simple practical protocol for statistical significance test selection in NLP setups and accompany this protocol with a brief survey of the most relevant tests. We then survey recent empirical papers published in ACL and TACL during 2017 and show that while our community assigns great value to experimental results, statistical significance testing is often ignored or misused. We conclude with a brief discussion of open issues that should be properly addressed so that this important tool can be applied. in NLP research in a statistically sound manner.",
}

@inproceedings{berg-kirkpatrick,
    title = "An Empirical Investigation of Statistical Significance in {NLP}",
    author = "Berg-Kirkpatrick, Taylor  and
      Burkett, David  and
      Klein, Dan",
    booktitle = "Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning",
    month = jul,
    year = "2012",
    address = "Jeju Island, Korea",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/D12-1091",
    pages = "995--1005",
}

@Book{bootstrap,
  Title                    = {An Introduction to the Bootstrap},
  Author                   = {Bradley Efron and Robert J. Tibshirani},
  Publisher                = {Chapman \& Hall/CRC},
  Year                     = {1993},

  Address                  = {Boca Raton, Florida, USA},
  Number                   = {57},
  Series                   = {Monographs on Statistics and Applied Probability}
}

@inproceedings{entropy_reg,
title	= {Regularizing Neural Networks by Penalizing Confident Output Distributions},
author	= {Gabriel Pereyra and George Tucker and Jan Chorowski and Łukasz Kaiser and Geoffrey Hinton},
year	= {2017},
URL	= {https://arxiv.org/abs/1701.06548}
}

@InProceedings{a3c,
  title = 	 {Asynchronous Methods for Deep Reinforcement Learning},
  author = 	 {Volodymyr Mnih and Adria Puigdomenech Badia and Mehdi Mirza and Alex Graves and Timothy Lillicrap and Tim Harley and David Silver and Koray Kavukcuoglu},
  booktitle = 	 {Proceedings of The 33rd International Conference on Machine Learning},
  pages = 	 {1928--1937},
  year = 	 {2016},
  editor = 	 {Maria Florina Balcan and Kilian Q. Weinberger},
  volume = 	 {48},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {New York, New York, USA},
  month = 	 {20--22 Jun},
  publisher = 	 {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v48/mniha16.pdf},
  url = 	 {http://proceedings.mlr.press/v48/mniha16.html},
  abstract = 	 {We propose a conceptually simple and lightweight framework for deep reinforcement learning that uses asynchronous gradient descent for optimization of deep neural network controllers. We present asynchronous variants of four standard reinforcement learning algorithms and show that parallel actor-learners have a stabilizing effect on training allowing all four methods to successfully train neural network controllers. The best performing method, an asynchronous variant of actor-critic, surpasses the current state-of-the-art on the Atari domain while training for half the time on a single multi-core CPU instead of a GPU. Furthermore, we show that asynchronous actor-critic succeeds on a wide variety of continuous motor control problems as well as on a new task of navigating random 3D mazes using a visual input.}
}

@article{hernandez2018data,
  title={Data augmentation instead of explicit regularization},
  author={Hern{\'a}ndez-Garc{\'\i}a, Alex and K{\"o}nig, Peter},
  journal={arXiv preprint arXiv:1806.03852},
  year={2018}
}

@article{tune,
    title={Tune: A Research Platform for Distributed Model Selection and Training},
    author={Liaw, Richard and Liang, Eric and Nishihara, Robert
            and Moritz, Philipp and Gonzalez, Joseph E and Stoica, Ion},
    journal={arXiv preprint arXiv:1807.05118},
    year={2018}
}

@Misc{pytables,
  author =    {{PyTables Developers Team}},
  title =     {{PyTables}: Hierarchical Datasets in {Python}},
  year =      {2002-2019},
  url = "http://www.pytables.org/"
}

@ONLINE{hdf5,
    author = {{The HDF Group}},
    title = "{Hierarchical Data Format, version 5}",
    year = {1997-2019},
    note = {http://www.hdfgroup.org/HDF5/}
}

@article{ahmed2018understanding,
  title={Understanding the impact of entropy in policy learning},
  author={Ahmed, Zafarali and Roux, Nicolas Le and Norouzi, Mohammad and Schuurmans, Dale},
  journal={International Conference on Machine Learning (ICLM)},
  year={2019}
}
